{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat-Bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To create a virtual answering tool that will giving meaningful answer to all our questions using Artificial intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Pre-Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Loading Data Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chat_bot_faq=pd.read_csv(\"/home/admin1/phoenix/MyDoc/data_sets/chat_bot/Dataset_for_chatbot/Data.csv\",encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"......................Label Encoding Intent Column.......................\"\"\"\n",
    "le = LabelEncoder()\n",
    "le.fit(df_chat_bot_faq['Intent'])\n",
    "df_chat_bot_faq[\"intent_classes\"]=le.transform(df_chat_bot_faq['Intent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Method that will add <EOS> at the end of question and <SOS> at the end of answer\"\"\"\n",
    "def tagger(decoder_input_sentence,question):\n",
    "    if question:\n",
    "        return decoder_input_sentence+\" <EOS>\"\n",
    "    else:\n",
    "        return decoder_input_sentence+\"<SOS> \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Method to do the pre-processing of text\"\"\"\n",
    "def text_pre_processing(text,question=False):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"that is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"n'\", \"ng\", text)\n",
    "    text = re.sub(r\"'bout\", \"about\", text)\n",
    "    text = re.sub(r\"'til\", \"until\", text)\n",
    "    text = text.replace(\"?\",\"\")\n",
    "    text = text.replace(\",\",\"\")\n",
    "    return tagger(text,question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtaining the pre-processed questions in a list\n",
    "chat_questions_cleaned = []\n",
    "#obtaining the pre-processed answers in a list\n",
    "chat_answers_cleaned=[]\n",
    "chat_questions = df_chat_bot_faq['Question'].values\n",
    "chat_answers=df_chat_bot_faq['Answer'].values\n",
    "for question in chat_questions:\n",
    "    chat_questions_cleaned.append(text_pre_processing(question,True))\n",
    "for answer in chat_answers:\n",
    "    chat_answers_cleaned.append(text_pre_processing(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Making a new DataFrame Of pre-processed questions and answers\"\"\"\n",
    "cleaned_chat=pd.DataFrame({\"questions\":chat_questions_cleaned,\"answers\":chat_answers_cleaned,\"intent\":df_chat_bot_faq['intent_classes'].values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Making a list Of all the sentences in questions and answers\"\"\"\n",
    "sentence_dict=[]\n",
    "for sentence in cleaned_chat[\"questions\"]:\n",
    "    sentence_dict.append(sentence)\n",
    "for sentence in cleaned_chat[\"answers\"]:\n",
    "    sentence_dict.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of question vector  :  (123, 413)\n",
      "Shape of answer vector  :  (123, 413)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Obtaining an object of countvectorizer and converting all sentences of question and answers into vectors\"\"\"\n",
    "vectorizer = CountVectorizer()\n",
    "word_dict_vector = vectorizer.fit(sentence_dict)\n",
    "questions_vector = vectorizer.transform(cleaned_chat['questions'])\n",
    "answers_vector =vectorizer.transform(cleaned_chat['answers'])\n",
    "print(\"Shape of question vector  : \",questions_vector.shape)\n",
    "print(\"Shape of answer vector  : \",answers_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Obtaing a dictionary of unique words in document and a integer as their key value\"\"\"\n",
    "dict_word={}\n",
    "list_word=vectorizer.get_feature_names()\n",
    "for i in range(len(list_word)):\n",
    "    dict_word[i]=list_word[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"XG-Boost classifier to find the intent of given question\"\"\"\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "classifier= GradientBoostingClassifier(n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(questions_vector,df_chat_bot_faq[\"intent_classes\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Method to find the most simillar question saved in our question to the question asked by user\"\"\"\n",
    "def find_question(vector,object_vectorizer,intent):\n",
    "    intent=intent[0]\n",
    "    tf_vectorizer=object_vectorizer\n",
    "    df=cleaned_chat.loc[cleaned_chat[\"intent\"]==intent]\n",
    "    tf_vectorizer.fit(np.concatenate((df.questions,df.answers)))\n",
    "    answer_vector = tf_vectorizer.transform(cleaned_chat.loc[cleaned_chat[\"intent\"]==intent][\"questions\"])\n",
    "    result =np.where(vector==1)[1]\n",
    "    result =[dict_word[i] for i in result]\n",
    "    inp_ans_vec = tf_vectorizer.transform(result)\n",
    "    simillarities = cosine_similarity(inp_ans_vec,answer_vector)\n",
    "    closest = np.argmax(simillarities,axis=1)\n",
    "    return df.questions.iloc[closest].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Method to return the answer to the question asked\"\"\"\n",
    "def return_result(object_vectorizer,intent,vector):\n",
    "    intent=intent[0]\n",
    "    tf_vectorizer=object_vectorizer\n",
    "    df=df_chat_bot_faq.loc[df_chat_bot_faq[\"intent_classes\"]==intent]\n",
    "    answer_vector_obj = tf_vectorizer.fit(np.concatenate((df.Question,df.Answer)))\n",
    "    ques_vector = tf_vectorizer.transform(df_chat_bot_faq.loc[df_chat_bot_faq[\"intent_classes\"]==intent][\"Question\"].values)\n",
    "    result =np.where(vector==1)[1]\n",
    "    result =[dict_word[i] for i in result]\n",
    "    inp_ans_vec = tf_vectorizer.transform(result)\n",
    "    simillarities = cosine_similarity(inp_ans_vec,ques_vector)\n",
    "    closest = np.argmax(simillarities,axis=1)\n",
    "    return df.Answer.iloc[closest].values[0]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Our Model and Other Important Objects in Pickel File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/admin1/phoenix/repos/project_with_phoenix/chat_bot/chat_bot/pkl_objects/cleaned_chat.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "path_of_pkl_objects=\"/home/admin1/phoenix/repos/project_with_phoenix/chat_bot/chat_bot/pkl_objects/\"\n",
    "joblib.dump(chat_questions_cleaned,path_of_pkl_objects+\"chat_questions_cleaned.pkl\")\n",
    "joblib.dump(chat_answers_cleaned,path_of_pkl_objects+\"chat_answers_cleaned.pkl\")\n",
    "joblib.dump(sentence_dict,path_of_pkl_objects+\"sentence_dict.pkl\")\n",
    "joblib.dump(dict_word,path_of_pkl_objects+\"dict_word.pkl\")\n",
    "joblib.dump(vectorizer,path_of_pkl_objects+\"count_vectorizer.pkl\")\n",
    "joblib.dump(classifier,path_of_pkl_objects+\"classifier.pkl\")\n",
    "joblib.dump(df_chat_bot_faq,path_of_pkl_objects+\"df_chat_bot_faq.pkl\")\n",
    "joblib.dump(cleaned_chat,path_of_pkl_objects+\"cleaned_chat.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
